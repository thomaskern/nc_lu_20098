\documentclass[12pt]{article}
\def\x#1#2{$\mathbb{#1}^#2$} 
\def\n#1{\x#1}

\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{mypriptrt}
\usepackage{subfigure}
\usepackage{epic}


\title{NC LU - Abgabe 1} 
\author{Aidoma, Kern, Weichselbaum}

\abstract{
	Documentation for the first exercise of Neural Computation LU, Group 8.
}
\begin{document}
	
\maketitle	
	

\section{Introduction}

The exercises are split up into several files. However, for convenience purposes all exercises can be executed by the function ex in the m-file named 'ex.m'.

\section{Exercise 1.1}
\subsection{Exercise 1.1.1}
\textit{Stellen Sie die Lage der Datenvektoren und ihre labels graphisch dar.}

\begin{figure}[htp]
	\centering
	\includegraphics[width=1\textwidth]{ab1_1_1.png}
	\caption{Dataset generated with genData(50,2)}
\end{figure}

\subsection{Exercise 1.1.2}

\textit{Untersuchen sie den Trainingsalgorithmus: Wieviele Iterationen werden benoetigt, bis sich weight-Vektor $w$ im Fall von linear separierbaren Daten nicht mehr andert?}
\\
It takes 9 epochs until the weight vector doesn't change. At this point, the algorithm stops because all of the data entries are successfully classified.
\\
\\
\textit{Wie veraendert sich der w waehrend des Trainings?}
\\
The weight vector is changed at each iteration IFF the data entry is misclassified. If it is misclassified the product of gamma, data entry and target for the data entry is added to the current weight vector.
\\
\\

\textit{Welchen Einfluss hat die Schrittweite?}
\\
Gamma has a huge impact on the weight vector and number of epochs required to successfully classify all the entries. In our randomly generated dataset (1.1.1), changing gamma from 0.1 to 0.3 resulted in 7 epochs instead of 9 epochs (win of 22\%) as well as a value-bloated weight vector (end weight vector:  [5.2000 0.5503 -2.1547] instead of [5.2000 0.5503 -2.1547]).
\\
\\


\textit{Plotten Sie die Daten und Entscheidungsgrenze in \n{R2}}
\\
TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
\\
\\

\textit{Wie ist das Verhalten bei nicht linear separierbaren Daten?}
\\
Unfortunately, the algorithm runs until maxIts (variable setting the maximum of possible epochs) is reached. Since the data is not linearly seperable there will always be a data entry on the wrong side of the hyperplane and therefor rotating it will not result in a success. The algorithm would run indefinitely without maxIts. 

\subsection{Exercise 1.1.3}
\textit{Untersuchen Sie die Leistung des trainierten Perzeptrons auf dem Testset abhaengig von der Groesse des Trainingsets.}
\\
Figure 2 shows the differences in 20\% split steps.
\\
\begin{figure}[htp]
	\centering
	\includegraphics[width=0.8\textwidth]{ab1_1_3}
	\caption{Our randomly generated dataset, genData(50,2)}
\end{figure}

\textit{Stellen Sie fuer einen Vergleich die wahren und die vom Perzeptron generierten Datenlabels graphisch dar.}
\\
This is answered/shown in 1.1.3.

\section{Exercise 1.2}
\subsection{Exercise 1.2.1}
TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
\end{document}


